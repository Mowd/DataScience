{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Naive Bayes spam filter using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "In this step, we load the data from the file. Each sample is a single line in the file and has the following format\n",
    "\n",
    "*{spam_or_ham},{email_text}*\n",
    "\n",
    "The first part is the label that identifies whether the email is spam or ham (not spam), followed by the email text. For example:\n",
    "\n",
    "`Spam,<p>But few feere in nor revellers in pride the a. Ear fathers yes begun revellers blazon one but not of take high. In had his her satiety alone fulness he sins perchance in thence climes nine scorching weary drugged...`\n",
    "\n",
    "The data will be loaded into two lists. features - the raw text of the emails, and labels - 0 (ham) or 1 (spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no. of samples: 2100\n",
      "total no. of spam samples: 1043\n",
      "total no. of ham samples: 1057\n",
      "\n",
      "Print a random sample for inspection:\n",
      "example feature: <p>And muse adieu bacchanals fulness tear nor revel prose childe. Or feels his mighty start childe whilome girls sight to third the name harolds longed oft. From if a shades mirthful who. Sorrow might they a his monastic in to sea charms apart to almost wassailers mine glare but he despair.</p><p>His disappointed none or childe change along and day suits full uses sea waste in the degree. Start himnot save aye but few to she such third present. For bower flow riot change sore high did and wandered tis from. Name flee bidding deemed ofttimes chaste would. Childe he had were whom. Not and yes the then childe he near long moths ah might and glee still bower lands before the. His to cell. Of caught other than might scape nor soon to ungodly.</p>\n",
      "example label: 1 (spam)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def read_file(path):\n",
    "    \"\"\"\n",
    "    read and return all data in a file\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    load and return the data in features and labels lists\n",
    "    each item in features contains the raw email text\n",
    "    each item in labels is either 1(spam) or 0(ham) and identifies corresponding item in features\n",
    "    \"\"\"\n",
    "    # load all data from file\n",
    "    data_path = \"data/SpamDetectionData.txt\"\n",
    "    all_data = read_file(data_path)\n",
    "    \n",
    "    # split the data into lines, each line is a single sample\n",
    "    all_lines = all_data.split('\\n')\n",
    "\n",
    "    # each line in the file is a sample and has the following format\n",
    "    # it begins with either \"Spam,\" or \"Ham,\", and follows by the actual text of the email\n",
    "    # e.g. Spam,<p>His honeyed and land....\n",
    "    \n",
    "    # extract the feature (email text) and label (spam or ham) from each line\n",
    "    features = []\n",
    "    labels = []\n",
    "    for line in all_lines:\n",
    "        if line[0:4] == 'Spam':\n",
    "            labels.append(1)\n",
    "            features.append(line[5:])\n",
    "            pass\n",
    "        elif line[0:3] == 'Ham':\n",
    "            labels.append(0)\n",
    "            features.append(line[4:])\n",
    "            pass\n",
    "        else:\n",
    "            # ignore markers, empty lines and other lines that aren't valid sample\n",
    "            # print('ignore: \"{}\"'.format(line));\n",
    "            pass\n",
    "    \n",
    "    return features, labels\n",
    "    \n",
    "features, labels = load_data()\n",
    "\n",
    "print(\"total no. of samples: {}\".format(len(labels)))\n",
    "print(\"total no. of spam samples: {}\".format(labels.count(1)))\n",
    "print(\"total no. of ham samples: {}\".format(labels.count(0)))\n",
    "\n",
    "print(\"\\nPrint a random sample for inspection:\")\n",
    "random_idx = random.randint(0, len(labels))\n",
    "print(\"example feature: {}\".format(features[random_idx][0:]))\n",
    "print(\"example label: {} ({})\".format(labels[random_idx], 'spam' if labels[random_idx] else 'ham'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data - Split data randomly into training and test subsets\n",
    "Use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of train features: 1680\n",
      "no. of train labels: 1680\n",
      "no. of test features: 420\n",
      "no. of test labels: 420\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load features and labels\n",
    "features, labels = load_data()\n",
    "\n",
    "# split data into training / test sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, \n",
    "    labels, \n",
    "    test_size=0.2,   # use 10% for testing\n",
    "    random_state=42)\n",
    "\n",
    "print(\"no. of train features: {}\".format(len(features_train)))\n",
    "print(\"no. of train labels: {}\".format(len(labels_train)))\n",
    "print(\"no. of test features: {}\".format(len(features_test)))\n",
    "print(\"no. of test labels: {}\".format(len(labels_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data - Vectorize text data\n",
    "Use [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to vectorize text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorize email text into tfidf matrix\n",
    "# TfidfVectorizer converts collection of raw documents to a matrix of TF-IDF features.\n",
    "# It's equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "vectorizer = TfidfVectorizer(\n",
    "    input='content',     # input is actual text\n",
    "    lowercase=True,      # convert to lower case before tokenizing\n",
    "    stop_words='english' # remove stop words\n",
    ")\n",
    "features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "features_test_transformed  = vectorizer.transform(features_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Naive Bayes Classifier\n",
    "Use [MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) to train a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "\n",
    "def save(vectorizer, classifier):\n",
    "    '''\n",
    "    save classifier to disk\n",
    "    '''\n",
    "    with open('model.pkl', 'wb') as file:\n",
    "        pickle.dump((vectorizer, classifier), file)\n",
    "        \n",
    "def load():\n",
    "    '''\n",
    "    load classifier from disk\n",
    "    '''\n",
    "    with open('model.pkl', 'rb') as file:\n",
    "      vectorizer, classifier = pickle.load(file)\n",
    "    return vectorizer, classifier\n",
    "\n",
    "# train a classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(features_train_transformed, labels_train)\n",
    "\n",
    "# save the trained model\n",
    "save(vectorizer, classifier)\n",
    "\n",
    "# score the classifier accuracy\n",
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(features_test_transformed, labels_test) * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate F1 Score\n",
    "Calculate [F1 score](https://en.wikipedia.org/wiki/F1_score) using [sklearn metrics.f1_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "prediction = classifier.predict(features_test_transformed)\n",
    "fscore = metrics.f1_score(labels_test, prediction, average='macro')\n",
    "print(\"F score {:.2f}\".format(fscore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the trained classifier for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perform a test\n",
      "EMAIL: ['<p>Sick sea he uses might where each sooth would by he and dear friend then. Him this and did virtues it despair given and from be there to things though revel of. Felt charms waste said below breast. Nor haply scorching scorching in sighed vile me he maidens maddest. Alas of deeds monks. Dote my and was sight though. Seemed her feels he childe which care hill.</p><p>Of her was of deigned for vexed given. A along plain. Pile that could can stalked made talethis to of his suffice had. Superstition had losel the formed her of but not knew his departed bliss was the. Riot spent only tear childe. Ere in a disporting more. Of lurked of mine vile be none childe that sore honeyed rill womans she where. She time all upon loathed to known. Seek atonement hall sore where ear. Ofttimes rake domestic dear the monks one thence come friends. A so none climes and kiss prose talethis her when and when then night bidding none childe. Will fame deemed relief delphis he whateer. Soon love scorching low of lone mine ee haply. Than oft lurked worse perchance and gild earth. Are did the losel of none would ofttimes his and. His in this basked such one at so was himnot native. Through though scene and now only hellas but nor later ne but one yet scene yea had.</p>']\n",
      "The email is SPAM\n"
     ]
    }
   ],
   "source": [
    "vectorizer, classifer = load()\n",
    "\n",
    "print('\\nPerform a test')                    \n",
    "#email_input = 'enter your email here'\n",
    "email_input = ['<p>Sick sea he uses might where each sooth would by he and dear friend then. Him this and did virtues it despair given and from be there to things though revel of. Felt charms waste said below breast. Nor haply scorching scorching in sighed vile me he maidens maddest. Alas of deeds monks. Dote my and was sight though. Seemed her feels he childe which care hill.</p><p>Of her was of deigned for vexed given. A along plain. Pile that could can stalked made talethis to of his suffice had. Superstition had losel the formed her of but not knew his departed bliss was the. Riot spent only tear childe. Ere in a disporting more. Of lurked of mine vile be none childe that sore honeyed rill womans she where. She time all upon loathed to known. Seek atonement hall sore where ear. Ofttimes rake domestic dear the monks one thence come friends. A so none climes and kiss prose talethis her when and when then night bidding none childe. Will fame deemed relief delphis he whateer. Soon love scorching low of lone mine ee haply. Than oft lurked worse perchance and gild earth. Are did the losel of none would ofttimes his and. His in this basked such one at so was himnot native. Through though scene and now only hellas but nor later ne but one yet scene yea had.</p>']\n",
    "email_input_transformed = vectorizer.transform(email_input)\n",
    "prediction = classifer.predict(email_input_transformed)\n",
    "\n",
    "print('EMAIL:', email_input)\n",
    "print('The email is', 'SPAM' if prediction else 'HAM')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
